{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://cocl.us/Data_Science_with_Scalla_top\"><img src = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/SC0103EN/adds/Data_Science_with_Scalla_notebook_top.png\" width = 750, align = \"center\"></a>\n",
    " <br/>\n",
    "<a><img src=\"https://ibm.box.com/shared/static/ugcqz6ohbvff804xp84y4kqnvvk3bq1g.png\" width=\"200\" align=\"center\"></a>\"\n",
    "\n",
    "# Basic Statistics and Data Types\n",
    "\n",
    "## Hypothesis Testing \n",
    "\n",
    "## Lesson Objectives \n",
    "\n",
    "After completing this lesson, you should be able to:\n",
    "\n",
    "-\tPerform hypothesis testing for goodness of fit and independence \n",
    "-\tPerform hypothesis testing for equality and probability distributions\n",
    "-\tPerform kernel density estimation \n",
    "\n",
    "## Hypothesis Testing \n",
    "\n",
    "- Used to determine whether a result is statistically significant, that is, whether it occurred by chance or not \n",
    "-\tSupported tests:\n",
    "  -\tPearson's Chi-Squared test for goodness of fit \n",
    "  -\tPearson's Chi-Squared test for independence\n",
    "-\tKolmogorov-Smirnov test for equality of distribution \n",
    "-\tInputs of type `RDD[LabeledPoint]` are also supported, enabling feature selection\n",
    "\n",
    "\n",
    "### Pearson's Chi-Squared Test for Goodness of Fit \n",
    "\n",
    "-\tDetermines whether an observed frequency distribution differs from a given distribution or not \n",
    "-\tRequires an input of type Vector containing the frequencies of the events \n",
    "-\tIt runs against a uniform distribution, if a second vector to test against is not supplied \n",
    "-\tAvailable as `chiSqTest`() function in Statistics \n",
    "\n",
    "\n",
    "\n",
    "### Libraries required for examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vec = [0.3,0.2,0.15,0.1,0.1,0.1,0.05]\n",
       "goodnessOfFitTestResult = \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "Chi squared test summary:\n",
       "method: pearson\n",
       "degrees of freedom = 6\n",
       "statistic = 0.295\n",
       "pValue = 0.999520973435643\n",
       "No presumption against null hypothesis: observed follows the same distribution as expected..\n",
       "Chi squared test summary:\n",
       "method: pearson\n",
       "degrees of freedom = 6\n",
       "statistic = 0.295\n",
       "pValue = 0.999520973435643\n",
       "No presumption against null hypothesis: observed follows the same distribution as expected..\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "import org.apache.spark.mllib.linalg.{Vector, Vectors}\n",
    "import org.apache.spark.mllib.linalg.{Matrix, Matrices}\n",
    "\n",
    "import org.apache.spark.mllib.stat.Statistics\n",
    "\n",
    "val vec: Vector = Vectors.dense(0.3, 0.2, 0.15, 0.1, 0.1, 0.1, 0.05)\n",
    "\n",
    "val goodnessOfFitTestResult = Statistics.chiSqTest(vec)\n",
    "\n",
    "goodnessOfFitTestResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson's Chi-Squared Test for Independence\n",
    "\n",
    "-\tDetermines whether unpaired observations on two variables are independent of each other \n",
    "-\tRequires an input of type Matrix, representing a contingency table, or an `RDD[LabeledPoint]`\n",
    "-\tAvailable as `chiSqTest()` function in Statistics \n",
    "-\tMay be used for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mat = \n",
       "independenceTestResult = \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "13.0  80.0\n",
       "47.0  11.0\n",
       "40.0  9.0\n",
       "Chi squared test summary:\n",
       "method: pearson\n",
       "degrees of freedom = 2\n",
       "statistic = 90.22588968846716\n",
       "pValue = 0.0\n",
       "Very strong presumption against null hypothesis: the occurrence of the outcomes is statistically independent..\n",
       "Chi squared test summary:\n",
       "method: pearson\n",
       "degrees of freedom = 2\n",
       "statistic = 90.22588968846716\n",
       "pValue = 0.0\n",
       "Very strong presumption against null hypothesis: the occurrence of the outcomes is statistically independent..\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "// Testing for Independence \n",
    "\n",
    "import org.apache.spark.mllib.linalg.{Matrix, Matrices}\n",
    "import org.apache.spark.mllib.stat.Statistics \n",
    "import org.apache.spark.rdd.RDD\n",
    "\n",
    "val mat: Matrix = Matrices.dense(3, 2,\n",
    "Array(13.0, 47.0, 40.0, 80.0, 11.0, 9.0))\n",
    "\n",
    "val independenceTestResult = Statistics.chiSqTest(mat)\n",
    "independenceTestResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "obs = ParallelCollectionRDD[0] at parallelize at <console>:36\n",
       "featureTestResults = \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "Array(Chi squared test summary:\n",
       "method: pearson\n",
       "degrees of freedom = 1\n",
       "statistic = 0.75\n",
       "pValue = 0.3864762307712326\n",
       "No presumption against null hypothesis: the occurrence of the outcomes is statistically independent.., Chi squared test summary:\n",
       "method: pearson\n",
       "degrees of freedom = 2\n",
       "statistic = 3.0000000000000004\n",
       "pValue = 0.22313016014843035\n",
       "No presumption against null hypothesis: the occurrence of the outcomes is statistically independent..)\n",
       "res14: Array[org.apache.sp...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "import org.apache.spark.mllib.regression.LabeledPoint\n",
    "import org.apache.spark.mllib.stat.test.ChiSqTestResult\n",
    "\n",
    "val obs: RDD[LabeledPoint] = sc.parallelize(Array(\n",
    "    LabeledPoint(0, Vectors.dense(1.0, 2.0)),\n",
    "    LabeledPoint(0, Vectors.dense(0.5, 1.5)),\n",
    "    LabeledPoint(1, Vectors.dense(1.0, 8.0))))\n",
    "\n",
    "val featureTestResults: Array[ChiSqTestResult] = Statistics.chiSqTest(obs)\n",
    "featureTestResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kolmogorov-Smirnov Test\n",
    "\n",
    "-\tDetermines whether nor not two probability distributions are equal \n",
    "-\tOne sample, two sided test \n",
    "-\tSupported distributions to test against:\n",
    "-\tnormal distribution (distName='norm')\n",
    "- customized cumulative density function (CDF)\n",
    "-\tAvailable as `kolmogorovSmirnovTest()` function in Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data = RandomRDD[5] at RDD at RandomRDD.scala:42\n",
       "testResult = \n",
       "data1 = RandomRDD[10] at RDD at RandomRDD.scala:42\n",
       "testResult1 = \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "Kolmogorov-Smirnov test summary:\n",
       "degrees of freedom = 0\n",
       "statistic = 0.12019890461912125\n",
       "pValue = 0.10230385223938121\n",
       "No presumption against null hypothesis: Sample follows theoretical distribution.\n",
       "Kolmogorov-Smirnov test summary:\n",
       "degrees of freedom = 0\n",
       "statistic = 0.5022419691869352\n",
       "pValue = -2.220446049250313E-16\n",
       "Very strong presumption against null hypothe...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "// Test for Equality of Distribution\n",
    "import org.apache.spark.mllib.random.RandomRDDs.normalRDD\n",
    "\n",
    "val data: RDD[Double] = normalRDD(sc, size=100, numPartitions=1, seed=13L)\n",
    "\n",
    "val testResult = Statistics.kolmogorovSmirnovTest(data, \"norm\", 0, 1)\n",
    " \n",
    "// Test for Equality of Distribution \n",
    "\n",
    "import org.apache.spark.mllib.random.RandomRDDs.uniformRDD\n",
    "\n",
    "val data1: RDD[Double] = uniformRDD(sc, size = 100, numPartitions=1, seed=13L)\n",
    "\n",
    "val testResult1 = Statistics.kolmogorovSmirnovTest(data1, \"norm\", 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Density Estimation \n",
    "\n",
    "-\tComputes an estimate of the probability density function of a random variable, evaluated at a given set of points \n",
    "-\tDoes not require assumptions about the particular distribution that the observed samples are drawn from \n",
    "-\tRequires an RDD of samples\n",
    "-\tAvailable as `estimate()` function in KernelDensity\n",
    "-\tIn Spark, only Gaussian kernel is supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data = RandomRDD[15] at RDD at RandomRDD.scala:42\n",
       "kd = org.apache.spark.mllib.stat.KernelDensity@946de4b\n",
       "densities = Array(0.13251324189510227, 0.2343205768786857, 0.37436865774453676, 0.2597908788293575, 0.11549809683090305)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "Array(0.13251324189510227, 0.2343205768786857, 0.37436865774453676, 0.2597908788293575, 0.11549809683090305)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "// Kernel Density Estimation I\n",
    "\n",
    "import org.apache.spark.mllib.stat.KernelDensity\n",
    "\n",
    "val data: RDD[Double] = normalRDD(sc, size=1000, numPartitions=1, seed=17L)\n",
    "\n",
    "val kd = new KernelDensity().setSample(data).setBandwidth(0.1)\n",
    "\n",
    "val densities = kd.estimate(Array(-1.5, -1, -0.5, 1, 1.5))\n",
    "\n",
    "densities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data = RandomRDD[16] at RDD at RandomRDD.scala:42\n",
       "kd = org.apache.spark.mllib.stat.KernelDensity@5e8846b9\n",
       "densities = Array(0.005891454217755318, 1.0011358547494325, 1.0157407141249963, 0.9352095006986689, 0.006607054892779689)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "Array(0.005891454217755318, 1.0011358547494325, 1.0157407141249963, 0.9352095006986689, 0.006607054892779689)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Kernel Density Estimation II \n",
    "\n",
    "val data: RDD[Double] = uniformRDD(sc, size=1000, numPartitions=1, seed=17L)\n",
    "\n",
    "val kd = new KernelDensity().setSample(data).setBandwidth(0.1)\n",
    "\n",
    "val densities = kd.estimate(Array(-0.25, 0.25, 0.5, 0.75, 1.25))\n",
    "\n",
    "densities "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson Summary\n",
    "\n",
    "-\tHaving completed this lesson, you should be able to:\n",
    "- Perform hypothesis testing for goodness of fit and independence \n",
    "-\tPerform hypothesis testing for equality of probability distributions \n",
    "-\tPerform kernel density estimation\n",
    "\n",
    "### About the Authors\n",
    "\n",
    "[Petro Verkhogliad](https://www.linkedin.com/in/vpetro) is Consulting Manager at Lightbend. He holds a Masters degree in Computer Science with specialization in Intelligent Systems. He is passionate about functional programming and applications of AI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
