{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://cocl.us/Data_Science_with_Scalla_top\"><img src = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/SC0103EN/adds/Data_Science_with_Scalla_notebook_top.png\" width = 750, align = \"center\"></a>\n",
    " <br/>\n",
    "<a><img src=\"https://ibm.box.com/shared/static/ugcqz6ohbvff804xp84y4kqnvvk3bq1g.png\" width=\"200\" align=\"center\"></a>\"\n",
    "\n",
    "# Linear Methods\n",
    "\n",
    "\n",
    "After completing this lesson you should be able to:\n",
    "\n",
    "* Understand the Pipeline API for Logistic Regression and Linear Least Squares\n",
    "* Perform classification with Logistic Regression\n",
    "* Perform regression with Linear Least Squares\n",
    "* Use regularization with Logistic Regression and Linear Least Squares\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "* Widely used to predict binary responses\n",
    "* Can be generalized into multinomial logistic regression\n",
    "\n",
    "The benefits of Logistic Regression are:\n",
    "\n",
    "* there are no tuning parameters\n",
    "* the prediction equation is simple and easy to implement\n",
    "\n",
    "## Continuing from previous example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "val spark = SparkSession.builder().getOrCreate()\n",
    "import spark.implicits._\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "import org.apache.spark.mllib.util.MLUtils.{\n",
    "  convertVectorColumnsFromML => fromML,\n",
    "  convertVectorColumnsToML => toML\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.util.MLUtils\n",
    " \n",
    "val data = toML(MLUtils.loadLibSVMFile(sc, \"/resources/data/sample_libsvm_data.txt\").toDF())\n",
    "\n",
    "val splitData = data.randomSplit(Array(0.7, 0.3))\n",
    "val trainingData = toML(splitData(0))\n",
    "val testData = toML(splitData(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.spark.ml.classification.BinaryLogisticRegressionSummary\n",
    "\n",
    "val logr = new LogisticRegression().setMaxIter(10).setRegParam(0.3).setElasticNetParam(0.8)\n",
    "\n",
    "val logrModel = logr.fit(trainingData)\n",
    "\n",
    "println(s\"Weights: ${logrModel.coefficients}\\nIntercept: ${logrModel.intercept}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "val trainingSummaryLR = logrModel.summary\n",
    "val objectiveHistoryLR = trainingSummaryLR.objectiveHistory\n",
    "println(objectiveHistoryLR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Least Squares\n",
    "\n",
    "- Most common formulation for regression problems\n",
    "- Average loss = Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.regression.LinearRegression\n",
    "\n",
    "val lr = new LinearRegression().setMaxIter(10).setRegParam(0.3).setElasticNetParam(0.8)\n",
    "\n",
    "val lrModel = lr.fit(trainingData)\n",
    "\n",
    "println(s\"Weights: ${lrModel.coefficients}\\nIntercept: ${lrModel.intercept}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "val trainingSummaryLLS = lrModel.summary\n",
    "val objectiveHistoryLLS = trainingSummaryLLS.objectiveHistory\n",
    "\n",
    "println(objectiveHistoryLLS)\n",
    "\n",
    "trainingSummaryLLS.residuals.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson Summary\n",
    "\n",
    "Having completed this lesson, you should be able to:\n",
    "\n",
    "- Understand the Pipelines API for Logistic Regression and Linear Least Squares\n",
    "- Perform classification with Logistic Regression\n",
    "- Perform classification with Linear Least Squares\n",
    "- Use regularization with Logistic Regression and Linear Least Squares\n",
    "\n",
    "### About the Authors\n",
    "\n",
    "[Petro Verkhogliad](https://www.linkedin.com/in/vpetro) is Consulting Manager at Lightbend. He holds a Masters degree in Computer Science with specialization in Intelligent Systems. He is passionate about functional programming and applications of AI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
