{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://cocl.us/Data_Science_with_Scalla_top\"><img src = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/SC0103EN/adds/Data_Science_with_Scalla_notebook_top.png\" width = 750, align = \"center\"></a>\n",
    " <br/>\n",
    "<a><img src=\"https://ibm.box.com/shared/static/ugcqz6ohbvff804xp84y4kqnvvk3bq1g.png\" width=\"200\" align=\"center\"></a>\"\n",
    "\n",
    "# Module 1: Basic Statistics and Data Types  \n",
    "\n",
    "## Local and Distributed Matrices\n",
    "\n",
    "## Lesson Objectives\n",
    "\n",
    "After completing this lesson, you should be able to:\n",
    "\n",
    "- Understand local and distributed matrices\n",
    "- Create dense and sparse matrices \n",
    "- Create different types of distributed matrices \n",
    "\n",
    "\n",
    "### Local Matrices \n",
    "- Natural extension of Vectors \n",
    "- Row and column indices are 0-based integers and values are doubles \n",
    "- Local matrices are stored on a single machine \n",
    "- MLlib's matrices can be either dense or sparse \n",
    "- Matrices are filled in column major order\n",
    "\n",
    "### Dense Matrices \n",
    "- A \"reshaped\" dense Vector \n",
    "- First two arguments specify dimensions of the matrix \n",
    "- Entries are stored in a single double array \n",
    "\n",
    "### A Dense Matrix Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.linalg.{Matrix, Matrices}\n",
    "\n",
    "Matrices.dense(3, 2, Array(1, 3, 5, 2, 4, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Matrices in Spark: Compressed Sparse Column (CSC) format\n",
    "\n",
    "Rows: 5\n",
    "Columns: 4\n",
    "Column pointers: `(0, 0, 1, 2, 2)`\n",
    "Row Indices: `(1, 3)`\n",
    "Non-zero values: `(34.0, 55.0)`\n",
    "\n",
    "### Sparse Matrix Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "val m = Matrices.sparse(5, 4, \n",
    "  Array(0, 0, 1, 2, 2), \n",
    "  Array(1, 3),\n",
    "  Array(34, 55)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed Matrices \n",
    "\n",
    "Distributed Matrices are where Spark starts to deliver significant value. They are stored in one or more RDDs.\n",
    "\n",
    "Three types have been implemented: \n",
    "- `RowMatrix`\n",
    "- `IndexedMatrix`\n",
    "- `CoodinateMatrix`\n",
    "\n",
    "Conversions may require an expensive global shuffle.\n",
    "\n",
    "\n",
    "#### RowMatrix\n",
    "\n",
    "- The most basic type of distributed matrix \n",
    "- It has no meaningful row indices, being only a collection of feature vectors \n",
    "- Backed by an RDD of its rows, where each row is a local vector `RowMatrix` \n",
    "- Assumes the number of columns is small enough to be stored in a local vector\n",
    "- Can be easily created from an instance of `RDD[Vector]`\n",
    "\n",
    "\n",
    "### A Simple RowMatrix Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import  org.apache.spark.rdd.RDD\n",
    "import  org.apache.spark.mllib.linalg.distributed.RowMatrix\n",
    "import  org.apache.spark.mllib.linalg.{Vector, Vectors}\n",
    "\n",
    "val rows: RDD[Vector] = sc.parallelize(Array(\n",
    "Vectors.dense(1.0, 2.0),\n",
    "Vectors.dense(4.0, 5.0), \n",
    "Vectors.dense(7.0, 8.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Simple RowMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "val mat: RowMatrix = new RowMatrix(rows)\n",
    "\n",
    "val m= mat.numRows()\n",
    "val n= mat.numCols()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IndexedRowMatrix\n",
    "\n",
    "- Similar to a `RowMatrix`\n",
    "- But it has meaningful row indices, which can be used for identifying rows and executing joins\n",
    "- Backed by an RDD of indexed rows, where each row is a tuple containing an index (long-typed) and a local vector \n",
    "- Easily created from an instance of `RDD[IndexedRow]`\n",
    "- Can be converted to a `RowMatrix` by calling `toRowMatrix()`\n",
    "\n",
    "\n",
    "### A Simple IndexedRowMatrix Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.linalg.distributed.{IndexedRow, IndexedRowMatrix, RowMatrix}\n",
    "\n",
    "val rows: RDD[IndexedRow] = sc.parallelize(Array(\n",
    "IndexedRow(0, Vectors.dense(1.0,2.0)),\n",
    "IndexedRow(1, Vectors.dense(4.0,5.0)),\n",
    "IndexedRow(2, Vectors.dense(7.0,8.0))))\n",
    "\n",
    "val idxMat: IndexedRowMatrix = new IndexedRowMatrix(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoordinateMatrix \n",
    "\n",
    "- Should be used only when both dimensions are huge and the matrix is very sparse\n",
    "- Backed up by an RDD of matrix entries, where each entry is a tuple `(i: Long, j: Long, value: Double)` where `i` is the row index `j` is the column index value is the entry value\n",
    "- Can be easily created from an instance of `RDD[MatrixEntry]`\n",
    "- Can be converted to an `IndexedRowMatrix` with sparse rows by calling `toIndexedRowMatrix()`\n",
    "\n",
    "\n",
    "### A Simple CoordinateMatrix Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.linalg.distributed.MatrixEntry\n",
    "import org.apache.spark.mllib.linalg.distributed.CoordinateMatrix\n",
    "\n",
    "val entries: RDD[MatrixEntry] = sc.parallelize(Array(\n",
    "MatrixEntry(0, 0, 9.0),\n",
    "MatrixEntry(1, 1, 8.0),\n",
    "MatrixEntry(2, 1, 6.0)))\n",
    "\n",
    "val coordMat: CoordinateMatrix = new CoordinateMatrix(entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the Authors\n",
    "\n",
    "[Petro Verkhogliad](https://www.linkedin.com/in/vpetro) is Consulting Manager at Lightbend. He holds a Masters degree in Computer Science with specialization in Intelligent Systems. He is passionate about functional programming and applications of AI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
