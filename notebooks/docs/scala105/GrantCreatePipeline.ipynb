{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://cocl.us/Data_Science_with_Scalla_top\"><img src = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/SC0103EN/adds/Data_Science_with_Scalla_notebook_top.png\" width = 750, align = \"center\"></a>\n",
    " <br/>\n",
    "<a><img src=\"https://ibm.box.com/shared/static/ugcqz6ohbvff804xp84y4kqnvvk3bq1g.png\" width=\"200\" align=\"center\"></a>\"\n",
    "\n",
    "# Module 5: Pipeline and Grid Search\n",
    "\n",
    "## Predicting Grant Applications: Building a Pipeline\n",
    "\n",
    "### Lesson Objectives\n",
    "\n",
    "* After completing this lesson, you should be able to:\n",
    "  - Understand the role of pipelines in spark.ml\n",
    "  - Use a pipeline to fit a model and make predictions\n",
    "  - Evaluate the results\n",
    "  \n",
    "### Key Concepts\n",
    "\n",
    "* Transformer\n",
    "  - an algorithm which transforms one DataFrame into another\n",
    "* Estimator\n",
    "  - an algorithm which can be fit on a DataFrame to produce a Transformer\n",
    "* Parameter\n",
    "  - there is a common API shared by Transformers and Estimators\n",
    "* Pipeline\n",
    "  - chains multiple Transformers together to specify a machine learning workflow\n",
    "* Evaluator\n",
    "  - measures the performance of an estimator or pipeline against some metric(s)\n",
    "  \n",
    "### Pipelines in spark.ml\n",
    "\n",
    "* Inspired by the scikit-learn project\n",
    "* Components:\n",
    "  - Transformers\n",
    "  - Estimators\n",
    "* Properties of components:\n",
    "  - Transformer.transform() and Estimator.fit() are stateless\n",
    "  - Each instance of Transformer/Estimator has a unique ID\n",
    "* A sequence of PipelineStages to be run in a specific order\n",
    "  - input DataFrame is transformed as it passes through each stage\n",
    "  - Transformer stages: `transform()` method is called on the DF\n",
    "  - Estimator stages: `fit()` method is called to produce a Transformer\n",
    "    - this Transformer becomes part of the Pipeline Model\n",
    "    - `transform()` method is called on the DF\n",
    "* Runtime checking is done using the DF's schema before actually running the Pipeline\n",
    "\n",
    "### Create the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "source": [
    "load grant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "val spark = SparkSession.builder().getOrCreate()\n",
    "import spark.implicits._\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val data = spark.read.\n",
    "  format(\"com.databricks.spark.csv\").\n",
    "  option(\"delimiter\", \"\\t\").\n",
    "  option(\"header\", \"true\").\n",
    "  option(\"inferSchema\", \"true\").\n",
    "  load(\"/resources/data/grantsPeople.csv\")\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "source": [
    "create features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "val researchers = data.\n",
    "  withColumn (\"phd\", data(\"With_PHD\").equalTo(\"Yes\").cast(\"Int\")).\n",
    "  withColumn (\"CI\", data(\"Role\").equalTo(\"CHIEF_INVESTIGATOR\").cast(\"Int\")).\n",
    "  withColumn(\"paperscore\", data(\"A2\") * 4 + data(\"A\") * 3)\n",
    "\n",
    "val grants = researchers.groupBy(\"Grant_Application_ID\").agg(\n",
    "  max(\"Grant_Status\").as(\"Grant_Status\"),\n",
    "  max(\"Grant_Category_Code\").as(\"Category_Code\"),\n",
    "  max(\"Contract_Value_Band\").as(\"Value_Band\"),\n",
    "  sum(\"phd\").as(\"PHDs\"),\n",
    "  when(max(expr(\"paperscore * CI\")).isNull, 0).\n",
    "    otherwise(max(expr(\"paperscore * CI\"))).as(\"paperscore\"),\n",
    "  count(\"*\").as(\"teamsize\"),\n",
    "  when(sum(\"Number_of_Successful_Grant\").isNull, 0).\n",
    "    otherwise(sum(\"Number_of_Successful_Grant\")).as(\"successes\"),\n",
    "  when(sum(\"Number_of_Unsuccessful_Grant\").isNull, 0).\n",
    "    otherwise(sum(\"Number_of_Unsuccessful_Grant\")).as(\"failures\")\n",
    ")\n",
    "\n",
    "grants.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "source": [
    "String Indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.feature.StringIndexer\n",
    "\n",
    "val value_band_indexer = new StringIndexer().\n",
    "  setInputCol(\"Value_Band\").\n",
    "  setOutputCol(\"Value_index\").\n",
    "  fit(grants)\n",
    "  \n",
    "val category_indexer = new StringIndexer().\n",
    "  setInputCol(\"Category_Code\").\n",
    "  setOutputCol(\"Category_index\").\n",
    "  fit(grants)\n",
    "  \n",
    "val label_indexer = new StringIndexer().\n",
    "  setInputCol(\"Grant_Status\").\n",
    "  setOutputCol(\"status\").\n",
    "  fit(grants)\n",
    "\n",
    "\n",
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "\n",
    "val assembler = new VectorAssembler().\n",
    "  setInputCols(Array(\n",
    "    \"Value_index\"\n",
    "    ,\"Category_index\"\n",
    "    ,\"PHDs\"\n",
    "    ,\"paperscore\"\n",
    "    ,\"teamsize\"\n",
    "    ,\"successes\"\n",
    "    ,\"failures\"\n",
    "  )).setOutputCol(\"assembled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "source": [
    "  Random Forest Classifier and Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.classification.RandomForestClassifier\n",
    "import org.apache.spark.ml.classification.RandomForestClassificationModel\n",
    "\n",
    "val rf = new RandomForestClassifier().\n",
    "  setFeaturesCol(\"assembled\").\n",
    "  setLabelCol(\"status\").\n",
    "  setSeed(42)\n",
    "\n",
    "import org.apache.spark.ml.Pipeline\n",
    "val pipeline = new Pipeline().setStages(Array(\n",
    "    value_band_indexer,\n",
    "    category_indexer,\n",
    "    label_indexer,\n",
    "    assembler,\n",
    "    rf)\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n",
    "val auc_eval = new BinaryClassificationEvaluator().\n",
    "  setLabelCol(\"status\").\n",
    "  setRawPredictionCol(\"rawPrediction\")\n",
    "auc_eval.getMetricName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "val tr = grants.filter(\"Grant_Application_ID < 6635\")\n",
    "val te = grants.filter(\"Grant_Application_ID >= 6635\")\n",
    "val training = tr.na.fill(0, Seq(\"PHDs\"))\n",
    "val test = te.na.fill(0, Seq(\"PHDs\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run and Evaluate the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "val model = pipeline.fit(training)\n",
    "val pipeline_results = model.transform(test)\n",
    "auc_eval.evaluate(pipeline_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the Authors\n",
    "\n",
    "[Petro Verkhogliad](https://www.linkedin.com/in/vpetro) is Consulting Manager at Lightbend. He holds a Masters degree in Computer Science with specialization in Intelligent Systems. He is passionate about functional programming and applications of AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
